{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1969530df041bdb0074cb1ffa50fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66ae847f8d04b6386bd2077f56bb50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97e65540c7a4a1f860e1a100f96e5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4745f6e70f3d41c6b629810b25d76790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ca88e895b14fc8917f253a4f04311f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Hello, how are you today?\n",
      "French: Bonjour, comment vous êtes-vous aujourd'hui?\n",
      "\n",
      "English: Hello, how are you today?\n",
      "German: Hallo, wie sind Sie heute?\n",
      "\n",
      "Spanish: ¿Cómo estás hoy?\n",
      "English: Cómo estás hoy?\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "class MultilingualTranslator:\n",
    "    def __init__(self, model_name=\"t5-base\"):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name, legacy=False)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)\n",
    "\n",
    "    def translate(self, text, source_lang, target_lang):\n",
    "        \"\"\"Translate text from source language to target language\"\"\"\n",
    "        # Make sure the source and target languages are supported\n",
    "        supported_lang = [\"English\", \"French\", \"German\", \"Spanish\"]\n",
    "        if source_lang not in supported_lang:\n",
    "            raise ValueError(f\"Unsupported source language: {source_lang}\")\n",
    "        if target_lang not in supported_lang:\n",
    "            raise ValueError(f\"Unsupported target language: {target_lang}\")\n",
    "        # Prepare the input text\n",
    "        task_prefix = f\"translate {source_lang} to {target_lang}\"\n",
    "        input_text = f\"{task_prefix}: {text}\"\n",
    "        # Tokenize and generate translation\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        inputs = inputs.to(self.device)\n",
    "        outputs = self.model.generate(**inputs, max_length=512, num_beams=4,\n",
    "                                      length_penalty=0.6, early_stopping=True)\n",
    "        # Decode and return translation\n",
    "        translation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return translation\n",
    "\n",
    "en_text = \"Hello, how are you today?\"\n",
    "es_text = \"¿Cómo estás hoy?\"\n",
    "translator = MultilingualTranslator(\"t5-base\")\n",
    "\n",
    "translation = translator.translate(en_text, \"English\", \"French\")\n",
    "print(f\"English: {en_text}\")\n",
    "print(f\"French: {translation}\")\n",
    "print()\n",
    "\n",
    "translation = translator.translate(en_text, \"English\", \"German\")\n",
    "print(f\"English: {en_text}\")\n",
    "print(f\"German: {translation}\")\n",
    "print()\n",
    "\n",
    "translation = translator.translate(es_text, \"Spanish\", \"English\")\n",
    "print(f\"Spanish: {es_text}\")\n",
    "print(f\"English: {translation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
