{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is deep learning?\n",
      "Best Answer: a subset of machine learning\n",
      "From Context: Deep learning is a subset of machine learning where artificial neural networks,\n",
      "    algorithms inspi...\n",
      "Confidence Score: 15.040037155151367\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'distilbert-base-uncased-distilled-squad'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Define multiple contexts\n",
    "question = \"What is deep learning?\"\n",
    "contexts = [\n",
    "    \"\"\"Machine learning is a field of inquiry devoted to understanding and building\n",
    "    methods that \"learn\", that is, methods that leverage data to improve performance\n",
    "    on some set of tasks. It is seen as a part of artificial intelligence.\"\"\",\n",
    "\n",
    "    \"\"\"Deep learning is a subset of machine learning where artificial neural networks,\n",
    "    algorithms inspired by the human brain, learn from large amounts of data. Deep\n",
    "    learning is behind many recent advances in AI, including computer vision and\n",
    "    speech recognition.\"\"\",\n",
    "\n",
    "    \"\"\"Natural Language Processing (NLP) is a field of AI that gives machines the\n",
    "    ability to read, understand, and derive meaning from human languages. It's used\n",
    "    in applications like chatbots, translation services, and sentiment analysis.\"\"\"\n",
    "]\n",
    "\n",
    "# Function to get answer from a single context\n",
    "def get_answer(question, context):\n",
    "    inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the most likely answer span\n",
    "    answer_start = torch.argmax(outputs.start_logits)\n",
    "    answer_end = torch.argmax(outputs.end_logits)\n",
    "\n",
    "    # Calculate the confidence score (simplified)\n",
    "    confidence = float(outputs.start_logits[0, answer_start] + outputs.end_logits[0, answer_end])\n",
    "\n",
    "    # Extract the answer\n",
    "    answer_tokens = inputs.input_ids[0, answer_start: answer_end + 1]\n",
    "    answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "    return answer, confidence\n",
    "\n",
    "# Get answers from all contexts\n",
    "answers_with_scores = [get_answer(question, context) for context in contexts]\n",
    "\n",
    "# Find the answer with the highest confidence score\n",
    "best_answer_idx = np.argmax([score for _, score in answers_with_scores])\n",
    "best_answer, best_score = answers_with_scores[best_answer_idx]\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Best Answer: {best_answer}\")\n",
    "print(f\"From Context: {contexts[best_answer_idx][:100]}...\")\n",
    "print(f\"Confidence Score: {best_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
